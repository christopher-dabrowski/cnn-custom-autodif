{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388e2651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/LocalDocuments/Studia/AlgorytmyWInzynieriiDanych/KM3_Repo`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09104e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../autodiff/graph.jl\")\n",
    "include(\"../autodiff/forward.jl\")\n",
    "include(\"../autodiff/backward.jl\")\n",
    "include(\"../autodiff/operators.jl\")\n",
    "include(\"../neuralnet/flux_like_api.jl\")\n",
    "\n",
    "using JLD2\n",
    "using Random\n",
    "using Statistics\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046060ce",
   "metadata": {},
   "source": [
    "The original test data is too large to upload to GitHub, so we are storing it as `.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32ad59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_dataset_prepared.jld2 already exists\n"
     ]
    }
   ],
   "source": [
    "if !isfile(\"../data/imdb_dataset_prepared.jld2\")\n",
    "  using ZipFile\n",
    "  r = ZipFile.Reader(\"../data/imdb_dataset_prepared.jld2.zip\")\n",
    "  for f in r.files\n",
    "    open(\"../data/\" * f.name, \"w\") do io\n",
    "      write(io, read(f))\n",
    "    end\n",
    "  end\n",
    "  close(r)\n",
    "  println(\"Extracted imdb_dataset_prepared.jld2 from zip file\")\n",
    "else\n",
    "  println(\"imdb_dataset_prepared.jld2 already exists\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61795d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binary_cross_entropy_loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux: DataLoader\n",
    "\n",
    "X_train = load(\"../data/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"../data/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"../data/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"../data/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "\n",
    "y_train = Float32.(y_train)\n",
    "y_test = Float32.(y_test)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "dataset = DataLoader((X_train, y_train), batchsize=batch_size, shuffle=true)\n",
    "\n",
    "input_neurons = size(X_train, 1)\n",
    "hidden_neurons = 32\n",
    "output_neurons = 1\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "ϵ = Constant(1e-7)\n",
    "binary_cross_entropy_loss(y, ŷ) = mean(Constant(-1.0) .* (y .* log.(ŷ .+ ϵ) .+ (Constant(1.0) .- y) .* log.(Constant(1.0) .- ŷ .+ ϵ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f686fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamState(Adam(0.001, 0.9, 0.999, 1.0e-8), Dict{Variable, Tuple{Array, Array, Int64}}(Variable([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], nothing, \"bias\") => ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0), Variable(Float32[-0.0008089907 0.008288155 … -0.0037912808 0.0027653973; -0.013782425 0.012998216 … 0.0036371658 0.004341168; … ; 0.013890246 0.0071280883 … -0.0058750412 0.0016605166; 0.018025497 0.013208701 … 0.0055700867 -0.0027483099], nothing, \"weight\") => ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], 0), Variable([0.0], nothing, \"bias\") => ([0.0], [0.0], 0), Variable(Float32[-0.20144412 0.2025319 … 0.2963485 -0.1369667], nothing, \"weight\") => ([0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0], 0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Dense(input_neurons, hidden_neurons, relu),\n",
    "    Dense(hidden_neurons, output_neurons, σ)\n",
    ")\n",
    "\n",
    "y = Variable(zeros(1, batch_size), name=\"y\")\n",
    "x = Variable(zeros(input_neurons, batch_size), name=\"x\")\n",
    "\n",
    "function loss(model, x, y)\n",
    "    ŷ = model(x)\n",
    "    E = binary_cross_entropy_loss(y, ŷ)\n",
    "    E.name = \"loss\"\n",
    "    return E, ŷ\n",
    "end\n",
    "\n",
    "otp = setup(Adam(), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ecfe748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (11.60s) \tTrain: (loss: 0.6399, acc: 0.7935)\n",
      "Epoch: 2 (4.04s) \tTrain: (loss: 0.4459, acc: 0.9159)\n",
      "Epoch: 3 (3.68s) \tTrain: (loss: 0.2892, acc: 0.9454)\n",
      "Epoch: 4 (3.62s) \tTrain: (loss: 0.1984, acc: 0.9644)\n",
      "Epoch: 5 (4.48s) \tTrain: (loss: 0.1420, acc: 0.9771)\n"
     ]
    }
   ],
   "source": [
    "L, ŷ_node = loss(model, x, y)\n",
    "graph = topological_sort(L)\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    t = @elapsed begin\n",
    "        for (xb, yb) in dataset\n",
    "            current_batch_size = size(xb, 2)\n",
    "\n",
    "            x.output .= xb\n",
    "            y.output .= yb\n",
    "\n",
    "            lval = forward!(graph)\n",
    "\n",
    "            for param in trainable(model)\n",
    "                param.gradient = nothing\n",
    "            end\n",
    "            backward!(graph)\n",
    "\n",
    "            update!(otp, model)\n",
    "\n",
    "            ŷ = ŷ_node.output\n",
    "            predictions = ŷ .> 0.5\n",
    "            targets = y.output .> 0.5\n",
    "            total_correct += count(predictions .== targets)\n",
    "            total_loss += lval[1] * current_batch_size\n",
    "            total_samples += current_batch_size\n",
    "        end\n",
    "    end\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (loss: %.4f, acc: %.4f)\",\n",
    "        epoch, t, avg_loss, avg_acc))\n",
    "\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
