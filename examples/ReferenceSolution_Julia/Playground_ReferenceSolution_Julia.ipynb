{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5eb34b8",
   "metadata": {},
   "source": [
    "A CNN created with Flux.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14898ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/LocalDocuments/Studia/AlgorytmyWInzynieriiDanych/KM3_Repo/examples/ReferenceSolution_Julia`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01043f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using JLD2\n",
    "X_train = load(\"../../data/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"../../data/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"../../data/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"../../data/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "embeddings = load(\"../../data/imdb_dataset_prepared.jld2\", \"embeddings\")\n",
    "vocab = load(\"../../data/imdb_dataset_prepared.jld2\", \"vocab\")\n",
    "nothing\n",
    "\n",
    "embedding_dim = size(embeddings,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb86b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12849-element Vector{String}:\n",
       " \"confined\"\n",
       " \"dumber\"\n",
       " \"henry\"\n",
       " \"abducted\"\n",
       " \"rises\"\n",
       " \"progression\"\n",
       " \"il\"\n",
       " \"gathered\"\n",
       " \"lovers\"\n",
       " \"cannibalistic\"\n",
       " ⋮\n",
       " \"poetic\"\n",
       " \"ponderous\"\n",
       " \"maybe\"\n",
       " \"towel\"\n",
       " \"uncut\"\n",
       " \"joint\"\n",
       " \"treacherous\"\n",
       " \"dev\"\n",
       " \"<pad>\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32d075d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×12849 Matrix{Float32}:\n",
       "  0.90951   -0.58014    0.27137   0.68397   …   0.45505     0.014323  0.0\n",
       " -0.20702   -1.1316     0.61347  -0.68729      -0.0014904  -0.74624   0.0\n",
       " -0.090611   0.44189   -0.52498   0.8797       -0.45487     0.35701   0.0\n",
       " -0.63721   -0.048199  -0.7617   -0.35249      -0.15543     0.75488   0.0\n",
       "  0.051387  -0.11754    0.37252   0.82288      -1.2866      0.11551   0.0\n",
       " -0.26292    0.97308    0.21401  -0.17179   …  -0.10727    -0.37074   0.0\n",
       "  0.14454    1.0075    -1.0817   -1.4887        0.37509     0.80859   0.0\n",
       "  0.40134   -1.2014     0.16501   0.98021       0.85616    -0.64355   0.0\n",
       "  0.17305   -1.2752    -0.45105   0.031865     -0.045315   -0.63822   0.0\n",
       " -0.23503    0.66842   -0.77013  -0.7007       -0.3152      0.74175   0.0\n",
       "  ⋮                                         ⋱                         \n",
       " -0.2502     0.54529    0.8323   -0.28752      -0.057228    0.36188   0.0\n",
       "  0.37538    0.68665   -0.63336   1.0756        1.1033     -0.79495   0.0\n",
       "  1.1403     0.52264   -0.32116  -0.82327       0.45043     0.30696   0.0\n",
       "  0.023104  -0.24133    0.21277   1.1868        0.03035     0.10232   0.0\n",
       " -0.7756     0.46689    0.47812  -1.314     …  -0.71941     0.25723   0.0\n",
       " -0.47407    0.15747   -0.41281  -0.84801       0.36268     0.82578   0.0\n",
       " -0.77261   -0.056616  -1.7192   -0.16565      -1.0215     -0.46867   0.0\n",
       " -0.60396    0.1722    -0.26018   0.10431       0.98155    -0.079873  0.0\n",
       " -0.31136    1.2622     0.57005  -1.1544       -0.50673    -0.89164   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfc0977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Embedding(12849 => 50),               \u001b[90m# 642_450 parameters\u001b[39m\n",
       "  var\"#13#14\"(),\n",
       "  Conv((3,), 50 => 8, relu),            \u001b[90m# 1_208 parameters\u001b[39m\n",
       "  MaxPool((8,)),\n",
       "  Flux.flatten,\n",
       "  Dense(128 => 1, σ),                   \u001b[90m# 129 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 5 arrays, \u001b[39m643_787 parameters, 2.456 MiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "model = Chain(\n",
    "    Flux.Embedding(length(vocab), embedding_dim),\n",
    "    x->permutedims(x, (2,1,3)),\n",
    "    Conv((3,), embedding_dim => 8, relu),\n",
    "    MaxPool((8,)),\n",
    "    Flux.flatten,\n",
    "    Dense(128, 1, σ)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38c70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Glove embeddings to Embedding layer\n",
    "model.layers[1].weight .= embeddings;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "638da747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input (token indices): [6391, 143, 286, 3838, 1529, 2329, 10682, 8101, 7377, 1934]\n",
      "130-element Vector{Int64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50×130 Matrix{Float32}:\n",
       "  0.16265    1.1607   0.0   0.44285   …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.37274    0.47395  0.0   0.31399      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.022479   1.3185   0.0   0.20969      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.50465    0.39748  0.0  -0.39017      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.27456   -0.45394  0.0   0.37531      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.093199   0.12834  0.0  -0.53613   …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.73615   -0.4484   0.0  -0.9145       0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.95033   -0.13     0.0   0.88797      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.54603    0.21566  0.0  -0.054453     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.15323    0.24585  0.0   0.14011      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  ⋮                                   ⋱            ⋮                   \n",
       " -0.52859   -0.12209  0.0   0.046413     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.40937    0.27572  0.0  -0.2176       0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.34248    0.34932  0.0  -0.31415      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.59462   -0.68974  0.0  -0.57202      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.26461    0.43281  0.0  -0.1538    …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.1421     0.44584  0.0  -0.055531     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.84558   -0.67216  0.0   0.215        0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.2768    -0.11291  0.0  -0.37976      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.36693   -0.23805  0.0  -0.30644      0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a simple model with just the embedding layer\n",
    "simple_model = Chain(Flux.Embedding(length(vocab), embedding_dim))\n",
    "simple_model.layers[1].weight .= embeddings\n",
    "\n",
    "# Take a sample input - first sequence from training data\n",
    "sample_input = X_train[:,1]\n",
    "println(\"Sample input (token indices): \", sample_input[1:10])  # Show first 10 tokens\n",
    "println(summary(sample_input))\n",
    "\n",
    "# Pass through embedding layer\n",
    "embedded_output = simple_model(sample_input)\n",
    "embedded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ea091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (35.34s) \tTrain: (l: 0.54, a: 0.73) \tTest: (l: 0.40, a: 0.82)\n",
      "Epoch: 2 (13.29s) \tTrain: (l: 0.33, a: 0.86) \tTest: (l: 0.34, a: 0.86)\n",
      "Epoch: 3 (14.54s) \tTrain: (l: 0.25, a: 0.90) \tTest: (l: 0.32, a: 0.87)\n",
      "Epoch: 4 (13.25s) \tTrain: (l: 0.19, a: 0.93) \tTest: (l: 0.33, a: 0.86)\n",
      "Epoch: 5 (13.39s) \tTrain: (l: 0.14, a: 0.95) \tTest: (l: 0.35, a: 0.86)\n"
     ]
    }
   ],
   "source": [
    "using Printf, Statistics\n",
    "\n",
    "dataset = Flux.DataLoader((X_train, y_train), batchsize=64, shuffle=true)\n",
    "\n",
    "loss(m, x, y) = Flux.Losses.binarycrossentropy(m(x), y)\n",
    "accuracy(m, x, y) = mean((m(x) .> 0.5) .== (y .> 0.5))\n",
    "\n",
    "opt = Optimisers.setup(Adam(), model)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in 1:epochs\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    t = @elapsed begin\n",
    "        for (x, y) in dataset\n",
    "            grads = Flux.gradient(model) do m\n",
    "                loss(m, x, y)\n",
    "            end\n",
    "            Optimisers.update!(opt, model, grads[1])\n",
    "            total_loss += loss(model, x, y)\n",
    "            total_acc += accuracy(model, x, y)\n",
    "            num_samples += 1\n",
    "        end\n",
    "\n",
    "        train_loss = total_loss / num_samples\n",
    "        train_acc = total_acc / num_samples\n",
    "\n",
    "        test_acc = accuracy(model, X_test, y_test)\n",
    "        test_loss = loss(model, X_test, y_test)\n",
    "    end\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f, a: %.2f) \\tTest: (l: %.2f, a: %.2f)\", \n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
